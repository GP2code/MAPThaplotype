{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPT - GenoML Analysis\n",
    "\n",
    "## GP2 NBA data release 7\n",
    "\n",
    "## Project: Exploring MAPT-containing H1 and H2 haplotypes  in Parkinson's Disease across diverse populations \n",
    "\n",
    "Version: Python/3.10.12\n",
    "\n",
    "Last Updated: MAY-2025\n",
    "\n",
    "Gene coordinates for the region of 17q21.31 (containing MAPT) from the UCSC Browser: chr17:42,800,001-46,800,000 (GRCh38/hg38)\n",
    "\n",
    "Notebook overview: In this notebook, we used GenoML to understad the relationship between 17q21.3 subhaplotypes and PD, applying machine learning via one-hot encoding and Extra Trees Classifier. Subhaplotypes were then ranked by predictive value using Gini impurity. Higher Gini importance indicated a subhaplotype's stronger role in distinguishing PD cases from controls.\n",
    "\n",
    "\n",
    "## Description:\n",
    "\n",
    "* Loading Python librariess, set paths to the GP2 data and defining functions\n",
    "* Install packages\n",
    "* Copy the files\n",
    "* Create a covariate file\n",
    "* Remove related individuals\n",
    "* Remove 'non-PD cases and -controls'\n",
    "* Extract the region of interest\n",
    "* Prepare file with the SNPs in the subhaplotype\n",
    "* Run GenoML\n",
    "    * Model individual tagging snps association with PD\n",
    "    * Model per-sample subhaplotype association with PD\n",
    "    * Run GenoML for subhaplotype vs PD analysis\n",
    "* Save output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Loading Python libraries and defining functions\n",
    "Installing packages\n",
    "Preparing input files:\n",
    "- Copying files \n",
    "- Remove related individuals\n",
    "- Remove non-PD case control individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "! pip install numba==0.60.0  joblib==1.4.2 pynndescent==0.5.13 matplotlib==3.9.2 numpy==1.26.4\\\n",
    " tables==3.10.1 pandas==2.2.2 pandas-plink==2.3.1 requests==2.32.3 scikit-learn==1.5.1\\\n",
    " scipy==1.14.1 seaborn==0.13.2 statsmodels==0.14.2 xgboost==2.0.3 umap-learn==0.5.6 xarray==2024.7.0 --user --force-reinstall --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify installations in notebook\n",
    "! pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Python libraries and defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the os package to interact with the environment\n",
    "import os\n",
    "\n",
    "# Bring in Pandas for Dataframe functionality\n",
    "import pandas as pd\n",
    "\n",
    "# Numpy for basics\n",
    "import numpy as np\n",
    "\n",
    "# Use StringIO for working with file contents\n",
    "from io import StringIO\n",
    "\n",
    "# Enable IPython to display matplotlib graphs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable interaction with the FireCloud API\n",
    "from firecloud import api as fapi\n",
    "\n",
    "# Import the iPython HTML rendering for displaying links to Google Cloud Console\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Import urllib modules for building URLs to Google Cloud Console\n",
    "import urllib.parse\n",
    "\n",
    "# BigQuery for querying data\n",
    "from google.cloud import bigquery\n",
    "\n",
    "#Import Sys\n",
    "import sys as sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility routine for printing a shell command before executing it\n",
    "def shell_do(command):\n",
    "    print(f'Executing: {command}', file=sys.stderr)\n",
    "    !$command\n",
    "    \n",
    "def shell_return(command):\n",
    "    print(f'Executing: {command}', file=sys.stderr)\n",
    "    output = !$command\n",
    "    return '\\n'.join(output)\n",
    "\n",
    "# Utility routine for printing a query before executing it\n",
    "def bq_query(query):\n",
    "    print(f'Executing: {query}', file=sys.stderr)\n",
    "    return pd.read_gbq(query, project_id=BILLING_PROJECT_ID, dialect='standard')\n",
    "\n",
    "# Utility routine for display a message and a link\n",
    "def display_html_link(description, link_text, url):\n",
    "    html = f'''\n",
    "    <p>\n",
    "    </p>\n",
    "    <p>\n",
    "    {description}\n",
    "    <a target=_blank href=\"{url}\">{link_text}</a>.\n",
    "    </p>\n",
    "    '''\n",
    "\n",
    "    display(HTML(html))\n",
    "\n",
    "# Utility routines for reading files from Google Cloud Storage\n",
    "def gcs_read_file(path):\n",
    "    \"\"\"Return the contents of a file in GCS\"\"\"\n",
    "    contents = !gsutil -u {BILLING_PROJECT_ID} cat {path}\n",
    "    return '\\n'.join(contents)\n",
    "    \n",
    "def gcs_read_csv(path, sep=None):\n",
    "    \"\"\"Return a DataFrame from the contents of a delimited file in GCS\"\"\"\n",
    "    return pd.read_csv(StringIO(gcs_read_file(path)), sep=sep, engine='python')\n",
    "\n",
    "# Utility routine for displaying a message and link to Cloud Console\n",
    "def link_to_cloud_console_gcs(description, link_text, gcs_path):\n",
    "    url = '{}?{}'.format(\n",
    "        os.path.join('https://console.cloud.google.com/storage/browser',\n",
    "                     gcs_path.replace(\"gs://\",\"\")),\n",
    "        urllib.parse.urlencode({'userProject': BILLING_PROJECT_ID}))\n",
    "\n",
    "    display_html_link(description, link_text, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up billing project and data path variables\n",
    "BILLING_PROJECT_ID = os.environ['GOOGLE_PROJECT']\n",
    "WORKSPACE_NAMESPACE = os.environ['WORKSPACE_NAMESPACE']\n",
    "WORKSPACE_NAME = os.environ['WORKSPACE_NAME']\n",
    "WORKSPACE_BUCKET = os.environ['WORKSPACE_BUCKET']\n",
    "\n",
    "WORKSPACE_ATTRIBUTES = fapi.get_workspace(WORKSPACE_NAMESPACE, WORKSPACE_NAME).json().get('workspace',{}).get('attributes',{})\n",
    "\n",
    "## Print the information to check we are in the proper release and billing \n",
    "## This will be different for you, the user, depending on the billing project your workspace is on\n",
    "print('Billing and Workspace')\n",
    "print(f'Workspace Name: {WORKSPACE_NAME}')\n",
    "print(f'Billing Project: {BILLING_PROJECT_ID}')\n",
    "print(f'Workspace Bucket, where you can upload and download data: {WORKSPACE_BUCKET}')\n",
    "print('')\n",
    "\n",
    "## GP2 v7.0\n",
    "## Explicitly define release v7.0 path \n",
    "GP2_RELEASE_PATH = 'gs://gp2tier2/path/to/release/7'\n",
    "GP2_CLINICAL_RELEASE_PATH = f'{GP2_RELEASE_PATH}/clinical_data'\n",
    "GP2_RAW_GENO_PATH = f'{GP2_RELEASE_PATH}/raw_genotypes'\n",
    "GP2_IMPUTED_GENO_PATH = f'{GP2_RELEASE_PATH}/imputed_genotypes'\n",
    "GP2_META_RELEASE_PATH = f'{GP2_RELEASE_PATH}/meta_data'\n",
    "GP2_SUMSTAT_RELEASE_PATH = f'{GP2_RELEASE_PATH}/summary_statistics'\n",
    "\n",
    "print('GP2 v7.0')\n",
    "print(f'Path to GP2 v7.0 Clinical Data @ `GP2_CLINICAL_RELEASE_PATH`: {GP2_CLINICAL_RELEASE_PATH}')\n",
    "print(f'Path to GP2 v7.0 Metadata @ `GP2_META_RELEASE_PATH`: {GP2_META_RELEASE_PATH}')\n",
    "print(f'Path to GP2 v7.0 Raw Genotype Data @ `GP2_RAW_GENO_PATH`: {GP2_RAW_GENO_PATH}')\n",
    "print(f'Path to GP2 v7.0 Imputed Genotype Data @ `GP2_IMPUTED_GENO_PATH`: {GP2_IMPUTED_GENO_PATH}')\n",
    "print(f'Path to GP2 v7.0 summary statistics: {GP2_SUMSTAT_RELEASE_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define ancestry\n",
    "ANCESTRY = \"AAC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Installing packages and softwares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Installing plink\n",
    "\n",
    "mkdir -p ~/tools\n",
    "cd ~/tools\n",
    "\n",
    "if test -e /home/jupyter/tools/plink; then\n",
    "echo \"Plink1.9 is already installed in /home/jupyter/tools/\"\n",
    "\n",
    "else\n",
    "echo -e \"Downloading plink \\n    -------\"\n",
    "wget -N http://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20190304.zip \n",
    "unzip -o plink_linux_x86_64_20190304.zip\n",
    "echo -e \"\\n plink downloaded and unzipped in /home/jupyter/tools \\n \"\n",
    "\n",
    "fi\n",
    "\n",
    "\n",
    "if test -e /home/jupyter/tools/plink2; then\n",
    "echo \"Plink2 is already installed in /home/jupyter/tools/\"\n",
    "\n",
    "else\n",
    "echo -e \"Downloading plink2 \\n    -------\"\n",
    "wget -N https://s3.amazonaws.com/plink2-assets/alpha6/plink2_linux_avx2_20250129.zip\n",
    "unzip -o plink2_linux_avx2_20250129.zip\n",
    "echo -e \"\\n plink2 downloaded and unzipped in /home/jupyter/tools \\n \"\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls /home/jupyter/tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# chmod plink 1.9 \n",
    "chmod u+x /home/jupyter/tools/plink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# chmod plink 2.0\n",
    "chmod u+x /home/jupyter/tools/plink2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a directory\n",
    "print(\"Making a working directory\")\n",
    "WORK_DIR = f'/home/jupyter/Team6_haplo/'\n",
    "shell_do(f'mkdir -p {WORK_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $ANCESTRY\n",
    "\n",
    "WORK_DIR='/home/jupyter/Team6_haplo/'\n",
    "cd $WORK_DIR\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retreive the files needed, including the genotype (iusing the imputed genotype files) and covariate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shell_do(f'gsutil -mu {BILLING_PROJECT_ID} ls {GP2_IMPUTED_GENO_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {GP2_IMPUTED_GENO_PATH}/{ANCESTRY}/chr17_{ANCESTRY}_* {WORK_DIR}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the covariate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} ls {GP2_CLINICAL_RELEASE_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {GP2_CLINICAL_RELEASE_PATH}/master_key_release7_final.csv {WORK_DIR}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove related individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select the file that matches with your population\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} ls {GP2_META_RELEASE_PATH}/related_samples/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {GP2_META_RELEASE_PATH}/related_samples/{ANCESTRY}_release7.related {WORK_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {GP2_RAW_GENO_PATH}/{ANCESTRY}/{ANCESTRY}_release7.eigenvec {WORK_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IDs are:\n",
    "ID1: Individual ID for the first individual of the pair\n",
    "ID2: Individual ID for the second individual of the pair\n",
    "We select to remove individuals in the ID1 and only exclude one person in the pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $ANCESTRY\n",
    "\n",
    "WORK_DIR='/home/jupyter/Team6_haplo/'\n",
    "cd $WORK_DIR\n",
    "\n",
    "\n",
    "cut -d, -f2 ${1}_release7.related > related_ids.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash -s $ANCESTRY\n",
    "\n",
    "WORK_DIR='/home/jupyter/Team6_haplo/'\n",
    "cd $WORK_DIR\n",
    "\n",
    "/home/jupyter/tools/plink2 \\\n",
    "--pfile chr17_${1}_release7 \\\n",
    "--remove related_ids.txt \\\n",
    "--make-pgen \\\n",
    "--out ${1}_release7_nonrelated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove non-PD case/control individuals\n",
    "\n",
    "Double-check with the numbers found here for your ancestry group before moving on: https://gp2.org/the-components-of-gp2s-fifth-data-release/\n",
    "\n",
    "The prune flag keeo only these with a plink phenotype of 1 or 0. We need to do this because the MAF will be different if these individuals are not removed (for the group all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s $ANCESTRY\n",
    "\n",
    "WORK_DIR='/home/jupyter/Team6_haplo/'\n",
    "cd $WORK_DIR\n",
    "\n",
    "/home/jupyter/tools/plink2 \\\n",
    "--pfile ${1}_release7_nonrelated \\\n",
    "--prune \\\n",
    "--make-pgen \\\n",
    "--out chr17_${1}_release7_nonrelated_pdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the region of interest (whole MAPT gene), update the variant IDs. and recode to plink v1.9 format (bed/bim/fam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $ANCESTRY\n",
    "\n",
    "WORK_DIR='/home/jupyter/Team6_haplo/'\n",
    "cd $WORK_DIR\n",
    "\n",
    "/home/jupyter/tools/plink2 \\\n",
    "--pfile chr17_${1}_release7_nonrelated_pdc \\\n",
    "--chr 17 \\\n",
    "--new-id-max-allele-len 64 \\\n",
    "--from-bp 45894527  \\\n",
    "--to-bp 48028334 \\\n",
    "--set-all-var-ids 'chr@_#_$r:$a' \\\n",
    "--make-pgen \\\n",
    "--out chr17_${1}_release7_MAPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $ANCESTRY\n",
    "\n",
    "WORK_DIR='/home/jupyter/Team6_haplo/'\n",
    "cd $WORK_DIR\n",
    "\n",
    "/home/jupyter/tools/plink2 \\\n",
    "--pfile chr17_${1}_release7_MAPT \\\n",
    "--chr 17 \\\n",
    "--from-bp 45894554  \\\n",
    "--to-bp 48028334 \\\n",
    "--rm-dup force-first \\\n",
    "--make-bed \\\n",
    "--out chr17_${1}_release7_MAPT \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR='/home/jupyter/Team6_haplo/'\n",
    "! ls $WORK_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the region of interest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are interested in the SNP rs1052553\n",
    "- This SNP was the one that they used in the Nigerian MAPT paper\n",
    "- This SNP will be used as a proxy for the H1/H2 haplotype\n",
    "- rs1052553 coordinates in GRCh38: 17:45996523\n",
    "- We will also add --mind to remove individuals that haven't been fully genotyped for this variant\n",
    "\n",
    "- Want to extract the H1/H2 tagging SNP, rs1052553, and the 6 subhaplotype tagging SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "Define the working directory, adjust this as necessary\n",
    "WORK_DIR='/home/jupyter/Team6_haplo/'\n",
    "cd $WORK_DIR\n",
    "\n",
    "# Create a file with the desired SNPs - need the coordinates\n",
    "cat > snps_to_keep.txt << EOF\n",
    "chr17_45908813_G:A\n",
    "chr17_45942346_G:A\n",
    "chr17_45977067_A:G\n",
    "chr17_45998697_C:T\n",
    "chr17_46003698_A:G\n",
    "chr17_46028029_A:G\n",
    "EOF\n",
    "\n",
    "# Echo the contents of the file to confirm it was created correctly\n",
    "cat snps_to_keep.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the SNPs\n",
    "We will also add --mind to remove individuals that haven't been fully genotyped for these variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%bash -s $ANCESTRY\n",
    "\n",
    "WORK_DIR='/home/jupyter/Team6_haplo/'\n",
    "cd $WORK_DIR\n",
    "\n",
    "/home/jupyter/tools/plink \\\n",
    "--bfile chr17_${1}_release7_MAPT \\\n",
    "--extract snps_to_keep.txt \\\n",
    "--chr 17 \\\n",
    "--mind 0.01 \\\n",
    "--recode \\\n",
    "--out ${1}_release7_MAPT_snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $ANCESTRY\n",
    "\n",
    "WORK_DIR='/home/jupyter/Team6_haplo/'\n",
    "cd $WORK_DIR\n",
    "\n",
    "cat ${1}_release7_MAPT_snps.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $ANCESTRY\n",
    "\n",
    "WORK_DIR='/home/jupyter/Team6_haplo/'\n",
    "cd $WORK_DIR\n",
    "\n",
    "/home/jupyter/tools/plink2 \\\n",
    "--bfile chr17_${1}_release7_MAPT \\\n",
    "--extract snps_to_keep.txt \\\n",
    "--rm-dup force-first \\\n",
    "--chr 17 \\\n",
    "--mind 0.01 \\\n",
    "--make-bed \\\n",
    "--out ${1}_release7_MAPT_snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat /home/jupyter/Team6_haplo/{ANCESTRY}_release7_MAPT_snps.bim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are two variants here with the same coordinates (At least for the CAS population). This is because there were multipel probes for the same variant during genotyping - the results for the variants should be indentical though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put together the covar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clin = pd.read_csv('/home/jupyter/Team6_haplo/master_key_release7_final.csv')\n",
    "clin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen = pd.read_csv(f'/home/jupyter/Team6_haplo/{ANCESTRY}_release7_nonrelated.psam', sep='\\t')\n",
    "gen.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pcs = pd.read_csv(f'/home/jupyter/Team6_haplo/{ANCESTRY}_release7.eigenvec', sep='\\t')\n",
    "pcs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen2 = pd.merge(gen, clin, left_on='#IID', right_on='GP2sampleID')\n",
    "gen2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen3 = pd.merge(gen2, pcs, left_on='#IID', right_on='IID')\n",
    "gen3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plink_clin = gen3[['#IID', 'SEX','PHENO1', 'age_at_sample_collection', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5','PC6', 'PC7', 'PC8', 'PC9','PC10' ]]\n",
    "plink_clin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set missing values to -9 (plink format)\n",
    "plink_clin.dropna(axis=0, subset=\"PHENO1\", inplace=True)\n",
    "plink_clin['age_at_sample_collection'] = plink_clin['age_at_sample_collection'].fillna(-9)\n",
    "plink_clin['SEX'] = plink_clin['SEX'].fillna(-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plink_clin[\"PHENO1\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename age_at_sample_collection  \n",
    "plink_clin = plink_clin.rename(columns={'age_at_sample_collection': 'AGE'})\n",
    "plink_clin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plink_clin.to_csv(f'/home/jupyter/Team6_haplo/{ANCESTRY}_covars.txt', sep='\\t', index=False, na_rep='-9',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariate_file = pd.read_csv(f\"/home/jupyter/Team6_haplo/{ANCESTRY}_covars.txt\", sep='\\t')\n",
    "pheno_column = covariate_file[[\"#IID\", \"PHENO1\"]].copy()\n",
    "pheno_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take modified covariate file and use it for genoml confounders\n",
    "covariate_file = pd.read_csv(f\"/home/jupyter/Team6_haplo/{ANCESTRY}_covars.txt\", sep='\\t')\n",
    "covariate_file.rename(columns={'#IID':'ID'}, inplace=True)\n",
    "# not including age because of missingness\n",
    "covariates_genoml = covariate_file[['ID', 'SEX','PC1', 'PC2', 'PC3', 'PC4', 'PC5']]\n",
    "covariates_genoml.to_csv(f\"/home/jupyter/GenoML/{ANCESTRY}_confounders.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename pheno column for processing with genoml\n",
    "pheno_file = pheno_column.rename(columns={'#IID':'ID', \"PHENO1\": \"PHENO\"}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_file[\"PHENO\"] = pheno_file[\"PHENO\"].astype(int)\n",
    "\n",
    "pheno_file[\"ID\"] = pheno_file[\"ID\"].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_file[\"PHENO\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map pheno to 0 for control, 1 for cases\n",
    "pheno_mapping = {1: 0, 2: 1}\n",
    "pheno_file['PHENO'] = pheno_file['PHENO'].map(pheno_mapping).astype('Int64')\n",
    "pheno_file[\"PHENO\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it in the GenoML work directory\n",
    "pheno_file.to_csv(f\"/home/jupyter/GenoML/{ANCESTRY}_pheno.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $ANCESTRY\n",
    "# copy over bfiles and files for analysis\n",
    "WORK_DIR='/home/jupyter/Team6_haplo/'\n",
    "cd $WORK_DIR\n",
    "cp ${1}_release7_MAPT_snps.fam ${1}_release7_MAPT_snps.bim ${1}_release7_MAPT_snps.bed /home/jupyter/GenoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash -s $ANCESTRY\n",
    "WORK_DIR='/home/jupyter/GenoML/'\n",
    "cd $WORK_DIR\n",
    "\n",
    "ls ${1}*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GenoML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a results and working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for GenoML results\n",
    "! mkdir -p /home/jupyter/GenoML/results\n",
    "! mkdir -p /home/jupyter/GenoML/results/{ANCESTRY}\n",
    "RESULTS_PATH = f'/home/jupyter/GenoML/results/{ANCESTRY}/'\n",
    "# move into outer project folder\n",
    "%cd /home/jupyter/GenoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model individual tagging snps association with PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run Genoml\n",
    "## Geno Input: 6 tagging snps in MAPT region\n",
    "## Feature Selection: 100 trees\n",
    "## Pheno Input: PD cases and healthy controls\n",
    "! genoml discrete supervised munge \\\n",
    "--geno {ANCESTRY}_release7_MAPT_snps \\\n",
    "--prefix results/{ANCESTRY}/{ANCESTRY} \\\n",
    "--skip_prune yes \\\n",
    "--feature_selection 100 \\\n",
    "--pheno {ANCESTRY}_pheno.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ranking of the tagging SNPS and their score\n",
    "! cp results/{ANCESTRY}/{ANCESTRY}.approx_feature_importance.txt results/{ANCESTRY}_snp_rank.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat results/{ANCESTRY}_snp_rank.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /home/jupyter/Team6_haplo/snps_to_keep.txt /home/jupyter/GenoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat snps_to_keep.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /home/jupyter/Team6_haplo/chr17_EUR_release7_MAPT.* /home/jupyter/GenoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/jupyter/GenoML\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model per-sample subhaplotype association with PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# recode the PLINK files\n",
    "for i in AAC AFR AJ AMR CAH CAS EAS EUR FIN MDE SAS; do\n",
    "/home/jupyter/tools/plink --bfile /home/jupyter/GenoML/${i}_release7_MAPT_snps --recode A --real-ref-alleles --out /home/jupyter/GenoML/${i}_r7_MAPT_snps_recode --output-missing-genotype 'N'\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = \"/home/jupyter/GenoML\"\n",
    "ancestry = \"SAS\"\n",
    "recode = pd.read_csv(f\"{WORK_DIR}/{ancestry}_r7_MAPT_snps_recode.raw\", sep = \" \")\n",
    "recode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recode.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form subhaplotype group for each sample, using the recoded genotype file\n",
    "\n",
    "WORK_DIR = \"/home/jupyter/GenoML\"\n",
    "ancestry = \"SAS\"\n",
    "recode = pd.read_csv(f\"{WORK_DIR}/{ancestry}_r7_MAPT_snps_recode.raw\", sep = \" \")\n",
    "snp_45908813 = {0: \"G\", 1: \"A\", 2:\"A\"}\n",
    "snp_45942346 = {0: \"G\", 1: \"A\", 2:\"A\"}\n",
    "snp_45977067 = {0: \"A\", 1: \"G\", 2:\"G\"}\n",
    "snp_45998697 = {0: \"C\", 1: \"T\", 2:\"T\"}\n",
    "snp_46003698 = {0: \"A\", 1: \"G\", 2:\"G\"}\n",
    "snp_46028029 = {0: \"A\", 1: \"G\", 2:\"G\"}\n",
    "\n",
    "def map_column(recode_df, column_list, map_list):\n",
    "    \"\"\"\n",
    "    Forms a 6 SNP subhaplotype group based on a recoded genotype file, and adds it to the dataframe\n",
    "    Params:\n",
    "        recode_df: recoded data frame\n",
    "        column_list: list of the tagging SNP columns\n",
    "        map_list: list of mappings for each value in the recode column, to the appropriate genotype\n",
    "    \n",
    "    Returns:\n",
    "        recoded_df: recoded dataframe with additional 'Haplotype' column \n",
    "    \"\"\"\n",
    "    recoded_df = recode_df.copy()\n",
    "    for i in range(len(column_list)):\n",
    "        col = column_list[i]\n",
    "        snp = map_list[i]\n",
    "        recoded_df[col] = recoded_df[col].map(snp).astype('str')\n",
    "    recoded_df['Haplotype'] = recoded_df[column_list].agg(''.join, axis=1)\n",
    "    return recoded_df\n",
    "\n",
    "col_list = ['chr17_45908813_G:A_A','chr17_45942346_G:A_A', 'chr17_45977067_A:G_G', 'chr17_45998697_C:T_T','chr17_46003698_A:G_G', 'chr17_46028029_A:G_G']\n",
    "map_list = [snp_45908813, snp_45942346, snp_45977067, snp_45998697, snp_46003698,snp_46028029]\n",
    "\n",
    "recoded_df = map_column(recode, col_list, map_list)\n",
    "recode_haplotype_df = pd.get_dummies(recoded_df, columns=[\"Haplotype\"], dtype=\"int\")\n",
    "haplotype_numerical = recode_haplotype_df.iloc[:, [1] + list(range(12, recode_haplotype_df.shape[1]))]\n",
    "haplotype_numerical = haplotype_numerical.rename(columns={'IID': 'ID'})\n",
    "haplotype_numerical\n",
    "haplotype_numerical.to_csv(f\"{WORK_DIR}/{ancestry}_haplotypes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "recoded_df[\"Haplotype\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run GenoML for subhaplotype vs PD analysis\n",
    "- Params:\n",
    "- addit_file = `{ancestry}_haplotypes.csv`\n",
    "- pheno_file = `{ancestry}_pheno.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for GenoML results\n",
    "ancestry = \"SAS\"\n",
    "! mkdir -p /home/jupyter/GenoML/haplo_results\n",
    "! mkdir -p /home/jupyter/GenoML/haplo_results/{ancestry}\n",
    "RESULTS_PATH = f'/home/jupyter/GenoML/haplo_results/{ancestry}/'\n",
    "# move into outer project folder\n",
    "%cd /home/jupyter/GenoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! genoml discrete supervised munge \\\n",
    "--addit {ancestry}_haplotypes.csv \\\n",
    "--prefix {RESULTS_PATH} \\\n",
    "--skip_prune yes \\\n",
    "--feature_selection 100 \\\n",
    "--pheno {ancestry}_pheno.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat {RESULTS_PATH}/.approx_feature_importance.txt\n",
    "! cp {RESULTS_PATH}/.approx_feature_importance.txt /home/jupyter/GenoML/haplo_results/{ancestry}_subhaplotype_feature_rank.txt\n",
    "! ls /home/jupyter/GenoML/haplo_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save files to workspace bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['AAC_subhaplotype_feature_rank.txt',\n",
    " 'AFR_subhaplotype_feature_rank.txt',\n",
    "'AJ_subhaplotype_feature_rank.txt',\n",
    "'AMR_subhaplotype_feature_rank.txt',\n",
    "'CAH_subhaplotype_feature_rank.txt',\n",
    "'CAS_subhaplotype_feature_rank.txt',\n",
    "'EAS_subhaplotype_feature_rank.txt',\n",
    "'EUR_subhaplotype_feature_rank.txt',\n",
    "'FIN_subhaplotype_feature_rank.txt',\n",
    "'MDE_subhaplotype_feature_rank.txt',\n",
    "'SAS_subhaplotype_feature_rank.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = '/home/jupyter/GenoML/haplo_results'\n",
    "for file in file_list:\n",
    "    shell_do(f'gsutil -mu {BILLING_PROJECT_ID} cp -r {WORK_DIR}/{file} {WORKSPACE_BUCKET}/GenoML_subhaplotype_results/{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil -u {BILLING_PROJECT_ID} ls $WORKSPACE_BUCKET/GenoML_subhaplotype_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
